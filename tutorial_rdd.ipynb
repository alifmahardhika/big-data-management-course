{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 32-bit ('LENOVO-nfkiuuwM': venv)",
   "display_name": "Python 3.8.2 32-bit ('LENOVO-nfkiuuwM': venv)",
   "metadata": {
    "interpreter": {
     "hash": "95bfffc8a73e7b9ce7e62a4fb79bbe83b0600692a798daa39700585e2260ff1d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# **Tutorial Basic Spark RDD**\n",
    "\n",
    "### Alif Mahardhika - 1706021934"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Karena saya menjalankan spark di machine windows pribadi, perlu ada konfigurasi imports tambahan:\n",
    "'''\n",
    "import findspark\n",
    "SPARK_HOME='C:\\spark\\spark-3.0.1-bin-hadoop2.7'\n",
    "findspark.init('C:/spark/spark-3.0.1-bin-hadoop2.7')\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "source": [
    "## Persiapan:\n",
    "\n",
    "Pada bagian ini sebuah spark context dan session di inisiasi. Saya juga mendefinisikan variabel header untuk menyimpan nama-nama column berdasarkan interpretasi saya."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Soal 2.1: Load data format ke RDD dan hitung jumlah user."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "#Inisiasi spark session\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Tutorial Basic Spark\") \\\n",
    ".config(\"spark.some.config.option\", \"some-value\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "\n",
    "#membaca file u.user sebagai csv\n",
    "users = spark.read.csv(path = \"ml-100k/u.user\", \n",
    "                       sep = '|',\n",
    "                       encoding = 'UTF-8',\n",
    "                       comment = None ,\n",
    "                       header = False ,\n",
    "                       inferSchema = True)\n",
    "\n",
    "users.rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of users: 943\n"
     ]
    }
   ],
   "source": [
    "# Soal nomor 1: hitung jumlah user\n",
    "\n",
    "print(\"Number of users: \" +str(users.rdd.count()))\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Soal 2.2: Buat fungsi map yang membagi user ke rentang usia 10-80 tahun buat bin sebesar 10 tahun setiap kategori."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat fungsi klasifikasi age_group antara 10-80 dengan ukuran range (bin) 10\n",
    "def classify_age_group(age):\n",
    "    if age > 10 and age <= 20:\n",
    "        return \"10-20\"\n",
    "    elif age > 20 and age <= 30:\n",
    "        return \"20-30\"\n",
    "    elif age > 30 and age <= 40:\n",
    "        return \"30-40\"\n",
    "    elif age > 40 and age <= 50:\n",
    "        return \"40-50\"\n",
    "    elif age > 50 and age <= 60:\n",
    "        return \"50-60\"\n",
    "    elif age > 60 and age <= 70:\n",
    "        return \"60-70\"\n",
    "    elif age > 70 and age <= 80:\n",
    "        return \"70-80\"\n",
    "    elif age <= 10:\n",
    "        return \"under_age\"\n",
    "    else:\n",
    "        return \"over_age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+---+------+-------------+-------+---------+\n|user_id|age|gender|   occupation|zipcode|age_group|\n+-------+---+------+-------------+-------+---------+\n|      1| 24|     M|   technician|  85711|    20-30|\n|      2| 53|     F|        other|  94043|    50-60|\n|      3| 23|     M|       writer|  32067|    20-30|\n|      4| 24|     M|   technician|  43537|    20-30|\n|      5| 33|     F|        other|  15213|    30-40|\n|      6| 42|     M|    executive|  98101|    40-50|\n|      7| 57|     M|administrator|  91344|    50-60|\n|      8| 36|     M|administrator|  05201|    30-40|\n|      9| 29|     M|      student|  01002|    20-30|\n|     10| 53|     M|       lawyer|  90703|    50-60|\n|     11| 39|     F|        other|  30329|    30-40|\n|     12| 28|     F|        other|  06405|    20-30|\n|     13| 47|     M|     educator|  29206|    40-50|\n|     14| 45|     M|    scientist|  55106|    40-50|\n|     15| 49|     F|     educator|  97301|    40-50|\n|     16| 21|     M|entertainment|  10309|    20-30|\n|     17| 30|     M|   programmer|  06355|    20-30|\n|     18| 35|     F|        other|  37212|    30-40|\n|     19| 40|     M|    librarian|  02138|    30-40|\n|     20| 42|     F|    homemaker|  95660|    40-50|\n+-------+---+------+-------------+-------+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# buat header baru untuk menyimpan column age_group\n",
    "header = ['user_id', 'age', 'gender', 'occupation','zipcode', 'age_group']\n",
    "\n",
    "# map users sehingga memiliki age group yang sesuai. age_group akan didefine sebagai kolom baru\n",
    "users_age_grouped = users.rdd.map(lambda x: [x['_c0'],x['_c1'],x['_c2'],x['_c3'],x['_c4'],classify_age_group(x['_c1'])])\n",
    "\n",
    "\n",
    "users_age_grouped_df = users_age_grouped.toDF(header)\n",
    "users_age_grouped_df.show()"
   ]
  },
  {
   "source": [
    "### Soal 2.3: Hitung jumlah pengguna berdasarkan profesi mereka dalam age_group 20-30 yang diberikan.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------+------------+\n|   occupation|num_of_users|\n+-------------+------------+\n|   technician|          14|\n|       writer|          16|\n|      student|          94|\n|        other|          42|\n|entertainment|           8|\n|   programmer|          34|\n|       artist|          13|\n|administrator|          24|\n|    librarian|          15|\n|    marketing|           7|\n|     educator|          13|\n|    executive|           7|\n|     engineer|          25|\n|     salesman|           4|\n|       lawyer|           5|\n|    scientist|           8|\n|       doctor|           2|\n|   healthcare|           4|\n|         none|           2|\n|    homemaker|           2|\n+-------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "# buat rdd baru dengan memfilter berdasarkan hasil klasifikasi rentang umur, lalu filter berdasarkan key (occupation) dan reduksi jika ada key sama dengan menambahkan\n",
    "users_20_30_occupations = users.rdd.filter(lambda x: classify_age_group(x['_c1']) == \"20-30\").map(lambda x: (x[3], 1)).reduceByKey(add)\n",
    "\n",
    "users_20_30_occupations.toDF(['occupation', 'num_of_users']).show()\n"
   ]
  },
  {
   "source": [
    "### Soal 2.4:  Hitung jumlah pengguna film dalam kelompok usia yang sama berdasarkan jenis kelamin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+------+-----+\n|age_group|gender|count|\n+---------+------+-----+\n|    10-20|     F|   42|\n|    10-20|     M|   65|\n|    20-30|     F|   87|\n|    20-30|     M|  252|\n|    30-40|     M|  162|\n|    30-40|     F|   61|\n|    40-50|     M|  109|\n|    40-50|     F|   58|\n|    50-60|     M|   60|\n|    50-60|     F|   23|\n|    60-70|     F|    2|\n|    60-70|     M|   19|\n|    70-80|     M|    1|\n|under_age|     M|    2|\n+---------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "users_gender_per_age_group = users_age_grouped_df.groupBy(\"age_group\",\"gender\").count().orderBy(asc('age_group'))\n",
    "\n",
    "users_gender_per_age_group.show()"
   ]
  },
  {
   "source": [
    "### Soal 2.5: Gunakan Akumulator untuk deteksi outlier dalam dataset film di atas. Asumsikan bahwa siapa saja yang termasuk dalam kelompok usia 80+ lebih sebagai outlier dan ditandai sebagai over_age dan siapa pun yang masuk dalam kelompok umur 0-10 juga outlier dan ditandai sebagai under_age"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Outlier Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Karena grouping outlier sudah dilakukan sebelumnya pada pengerjaan soal nomor2.2, pada bagian ini akan dilakukan penghitungan jumlah outlier menggunakan accumulator saja\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "accum = sc.accumulator(0)\n",
    "def count_outliers(row):\n",
    "    global accum\n",
    "    if(row['age_group'] == 'under_age' or row['age_group'] == 'over_age'):\n",
    "        accum +=1\n",
    "users_age_grouped_df.foreach(count_outliers)\n",
    "print('Outlier Count: ' + str(accum.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Soal 2.6: Periksa berapa banyak pengguna di bawah usia dan berapa banyak di atas usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = users_age_grouped_df.filter(\"age_group <=10 or age >80\")\n",
    "outliers.show()"
   ]
  }
 ]
}